{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align=\"center\">Machine Learning</h2> \n",
    "<h3 align=\"center\">Travis Millburn<br>Fall 2020</h3> \n",
    "\n",
    "<center>\n",
    "<img src=\"../images/logo.png\" alt=\"drawing\" style=\"width: 300px;\"/>\n",
    "</center>\n",
    "\n",
    "<h3 align=\"center\">Class 10: SVM + Boosting + Ensembles</h3> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Outline\n",
    "1. SVM\n",
    "2. Boosting\n",
    "3. Ensembles; SuperLearners\n",
    "4. Review: Bagging vs Boosting vs Ensembles\n",
    "5. Into to GRIDSEARCH\n",
    "6. Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "SVM:\n",
    "* Supervised learning\n",
    "* Used for Regression or Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"../images/svm_example.jpg\" alt=\"drawing\" style=\"width: 1200px;\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\"Kernel: A kernel is a similarity function for pattern analysis. It must be one of rbf/linear/poly/sigmoid/precomputed; default = “rbf” (radial basis function). Choosing the appropriate kernel will result in a better model fit\"\n",
    "\n",
    "\"Mastering Machine Learning with Python in Six Steps...\" - Manohar Swamynathan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>WorkClass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationNum</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>Race</th>\n",
       "      <th>Gender</th>\n",
       "      <th>CapitalGain</th>\n",
       "      <th>CapitalLoss</th>\n",
       "      <th>HoursPerWeek</th>\n",
       "      <th>NativeCountry</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32555</th>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>257302</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>154374</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>151910</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>201490</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>52</td>\n",
       "      <td>5</td>\n",
       "      <td>287927</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age  WorkClass  fnlwgt  Education  EducationNum  MaritalStatus  \\\n",
       "32555   27          4  257302          7            12              2   \n",
       "32556   40          4  154374         11             9              2   \n",
       "32557   58          4  151910         11             9              6   \n",
       "32558   22          4  201490         11             9              4   \n",
       "32559   52          5  287927         11             9              2   \n",
       "\n",
       "       Occupation  Relationship  Race  Gender  CapitalGain  CapitalLoss  \\\n",
       "32555          13             5     4       0            0            0   \n",
       "32556           7             0     4       1            0            0   \n",
       "32557           1             4     4       0            0            0   \n",
       "32558           1             3     4       1            0            0   \n",
       "32559           4             5     4       0        15024            0   \n",
       "\n",
       "       HoursPerWeek  NativeCountry  Income  \n",
       "32555            38             39       0  \n",
       "32556            40             39       1  \n",
       "32557            40             39       0  \n",
       "32558            20             39       0  \n",
       "32559            40             39       1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "from sklearn.svm import SVC\n",
    "import sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "col_names = [\n",
    "    \"Age\", \"WorkClass\", \"fnlwgt\", \"Education\", \"EducationNum\",\n",
    "    \"MaritalStatus\", \"Occupation\", \"Relationship\", \"Race\", \"Gender\",\n",
    "    \"CapitalGain\", \"CapitalLoss\", \"HoursPerWeek\", \"NativeCountry\", \"Income\"\n",
    "]\n",
    "\n",
    "df = pandas.read_csv('C:\\\\Users\\\\tmillburn\\\\Deep Basin Capital LP\\\\DBC-Dev - Documents\\\\notebooks\\\\Census Data\\\\adult.data')\n",
    "df.columns=col_names\n",
    "df['Income'] = df['Income'].apply(lambda x: 0 if x == ' <=50K' else 1)\n",
    "\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == type(object):\n",
    "        le = sklearn.preprocessing.LabelEncoder()\n",
    "        df[column] = le.fit_transform(df[column])\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X = df.drop(columns='Income')\n",
    "y = df['Income']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=555, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train CV Accuracy: 0.792 (+/- 0.001)\n",
      "Test Accuracy: 0.794 \n"
     ]
    }
   ],
   "source": [
    "# SVM TAKES A LONG TIME !!\n",
    "\n",
    "# Run in another notebook.\n",
    "\n",
    "SVM = SVC(random_state=0, probability=True)\n",
    "\n",
    "# Remember what is happening in cross validation ????\n",
    "scores = sklearn.model_selection.cross_val_score(SVM, X_train, y_train, cv=5, scoring=\"accuracy\")\n",
    "print(\"Train CV Accuracy: %0.3f (+/- %0.3f)\" % (scores.mean(), scores.std()))\n",
    "SVM.fit(X_train, y_train)\n",
    "print(\"Test Accuracy: %0.3f \" % (sklearn.metrics.accuracy_score(SVM.predict(X_test), y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Boosting\n",
    "\n",
    "\"The core concept of boosting is that rather than an independent individual hypothesis, combining hypotheses in a sequential order increases the accuracy.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"../images/boosting_ada.jpg\" alt=\"drawing\" style=\"width: 900px;\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"../images/boosting_w_weights.jpg\" alt=\"drawing\" style=\"width: 900px;\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common types of Boosting you will see:\n",
    "1. AdaBoost  \n",
    "2. Gradient Boost\n",
    "3. XGBoost (Extreme Gradient Boost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Bagging and Boosting\n",
    "* Sequential ensemble of models:  Boosting\n",
    "\n",
    "* Parallel ensemble of models:  Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train CV Accuracy: 0.864 (+/- 0.003) [GBC]\n",
      "Test Accuracy: 0.865 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "GBC = GradientBoostingClassifier(n_estimators = 100)\n",
    "scores = sklearn.model_selection.cross_val_score(GBC, X_train, y_train, cv=5, scoring=\"accuracy\")\n",
    "print(\"Train CV Accuracy: %0.3f (+/- %0.3f) [%s]\" % (scores.mean(), scores.std(), 'GBC'))\n",
    "GBC.fit(X_train, y_train)\n",
    "print(\"Test Accuracy: %0.3f \" % (sklearn.metrics.accuracy_score(GBC.predict(X_test), y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Hey that's pretty good!\n",
    "\n",
    "#### Let's compare to other estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train CV Accuracy: 0.864 (+/- 0.002) [ADBC]\n",
      "Test Accuracy: 0.864 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# We can specify a base model with AdaBoost.  Defaults to DecisionTreeClassifier\n",
    "\n",
    "ADBC = AdaBoostClassifier(n_estimators = 100)\n",
    "scores = sklearn.model_selection.cross_val_score(ADBC, X_train, y_train, cv=5, scoring=\"accuracy\")\n",
    "print(\"Train CV Accuracy: %0.3f (+/- %0.3f) [%s]\" % (scores.mean(), scores.std(), 'ADBC'))\n",
    "ADBC.fit(X_train, y_train)\n",
    "print(\"Test Accuracy: %0.3f \" % (sklearn.metrics.accuracy_score(ADBC.predict(X_test), y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train CV Accuracy: 0.772 (+/- 0.002) [knn]\n",
      "Test Accuracy: 0.779 \n"
     ]
    }
   ],
   "source": [
    "# What if we apply boosting to a KNN model instead of the DT ?\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "scores = sklearn.model_selection.cross_val_score(knn, X_train, y_train, cv=5, scoring=\"accuracy\")\n",
    "print(\"Train CV Accuracy: %0.3f (+/- %0.3f) [%s]\" % (scores.mean(), scores.std(), 'knn'))\n",
    "knn.fit(X_train, y_train)\n",
    "print(\"Test Accuracy: %0.3f \" % (sklearn.metrics.accuracy_score(knn.predict(X_test), y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold cross validation:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tmillburn\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\tmillburn\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\tmillburn\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train CV Accuracy: 0.787 (+/- 0.004) [Logistic Regression]\n",
      "Test Accuracy: 0.8034 \n",
      "Train CV Accuracy: 0.856 (+/- 0.004) [Random Forest]\n",
      "Test Accuracy: 0.8575 \n",
      "Train CV Accuracy: 0.772 (+/- 0.002) [KNeighbors]\n",
      "Test Accuracy: 0.7792 \n",
      "Train CV Accuracy: 0.808 (+/- 0.004) [Decision Tree]\n",
      "Test Accuracy: 0.8151 \n",
      "Train CV Accuracy: 0.864 (+/- 0.002) [Ada Boost]\n",
      "Test Accuracy: 0.8636 \n",
      "Train CV Accuracy: 0.848 (+/- 0.002) [Bagging]\n",
      "Test Accuracy: 0.8579 \n",
      "Train CV Accuracy: 0.864 (+/- 0.003) [Gradient Boosting]\n",
      "Test Accuracy: 0.8650 \n",
      "Train CV Accuracy: 0.866 (+/- 0.002) [XGBoost]\n",
      "Test Accuracy: 0.8709 \n"
     ]
    }
   ],
   "source": [
    "LR = LogisticRegression(solver='lbfgs', random_state=555)\n",
    "RF = RandomForestClassifier(n_estimators = 100, random_state=555)\n",
    "SVM = SVC(random_state=0, probability=True)\n",
    "KNC = KNeighborsClassifier()\n",
    "DTC = DecisionTreeClassifier()\n",
    "ABC = AdaBoostClassifier(n_estimators = 100)\n",
    "BC = BaggingClassifier(n_estimators = 100)\n",
    "GBC = GradientBoostingClassifier(n_estimators = 100)\n",
    "clf_XGB = XGBClassifier(n_estimators = 100, objective= 'binary:logistic', seed=555)\n",
    "clfs = []\n",
    "print('5-fold cross validation:\\n')\n",
    "for clf, label in zip([LR, RF, KNC, DTC, ABC, BC, GBC, clf_XGB],\n",
    "                      ['Logistic Regression',\n",
    "                       'Random Forest',\n",
    "                       #'Support Vector Machine',\n",
    "                       'KNeighbors',\n",
    "                       'Decision Tree',\n",
    "                       'Ada Boost',\n",
    "                       'Bagging',\n",
    "                       'Gradient Boosting',\n",
    "                       'XGBoost']):\n",
    "    scores = sklearn.model_selection.cross_val_score(clf, X_train, y_train, cv=5, scoring=\"accuracy\")\n",
    "    print(\"Train CV Accuracy: %0.3f (+/- %0.3f) [%s]\" % (scores.mean(), scores.std(), label))\n",
    "    md = clf.fit(X_train, y_train)\n",
    "    clfs.append(md)\n",
    "    print(\"Test Accuracy: %0.4f \" % (sklearn.metrics.accuracy_score(clf.predict(X_test), y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What if we want to create our own custom ensemble ??\n",
    "\n",
    "### This is python.  There is a library for that!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Discussion: Super Learners.\n",
    "\n",
    "<center>\n",
    "<img src=\"../images/ensemble.jpg\" alt=\"drawing\" style=\"width: 900px;\"/>\n",
    "</center>\n",
    "\n",
    "#### Also known as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MLENS] backend: threading\n"
     ]
    }
   ],
   "source": [
    "from mlens.ensemble import SuperLearner\n",
    "from mlens.model_selection import Evaluator\n",
    "from mlens.metrics import make_scorer\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#We'll use threading.  Discuss: threads vs processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# --- Build ---\n",
    "# Passing a scoring function will create cv scores during fitting\n",
    "# the scorer should be a simple function accepting to vectors and returning a scalar\n",
    "ensemble = SuperLearner(scorer=accuracy_score, random_state=555, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuperLearner(array_check=None, backend=None, folds=2,\n",
       "       layers=[Layer(backend='threading', dtype=<class 'numpy.float32'>, n_jobs=-1,\n",
       "   name='layer-1', propagate_features=None, raise_on_exception=True,\n",
       "   random_state=4782, shuffle=False,\n",
       "   stack=[Group(backend='threading', dtype=<class 'numpy.float32'>,\n",
       "   indexer=FoldIndex(X=None, folds=2, raise_on_ex...7358DC8>)],\n",
       "   n_jobs=-1, name='group-0', raise_on_exception=True, transformers=[])],\n",
       "   verbose=1)],\n",
       "       model_selection=False, n_jobs=None, raise_on_exception=True,\n",
       "       random_state=555, sample_size=20,\n",
       "       scorer=<function accuracy_score at 0x0000016CC7358DC8>,\n",
       "       shuffle=False, verbose=2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the first layer\n",
    "ensemble.add([KNC, LR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuperLearner(array_check=None, backend=None, folds=2,\n",
       "       layers=[Layer(backend='threading', dtype=<class 'numpy.float32'>, n_jobs=-1,\n",
       "   name='layer-1', propagate_features=None, raise_on_exception=True,\n",
       "   random_state=4782, shuffle=False,\n",
       "   stack=[Group(backend='threading', dtype=<class 'numpy.float32'>,\n",
       "   indexer=FoldIndex(X=None, folds=2, raise_on_ex...7358DC8>)],\n",
       "   n_jobs=-1, name='group-1', raise_on_exception=True, transformers=[])],\n",
       "   verbose=1)],\n",
       "       model_selection=False, n_jobs=None, raise_on_exception=True,\n",
       "       random_state=555, sample_size=20,\n",
       "       scorer=<function accuracy_score at 0x0000016CC7358DC8>,\n",
       "       shuffle=False, verbose=2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attach the final meta estimator\n",
    "ensemble.add_meta(LogisticRegression())\n",
    "#ensemble.add_meta(GradientBoostingClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting 2 layers\n",
      "Processing layer-1             "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tmillburn\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\tmillburn\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done | 00:00:01\n",
      "Processing layer-2             done | 00:00:00\n",
      "Fit complete                        | 00:00:01\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SuperLearner(array_check=None, backend=None, folds=2,\n",
       "       layers=[Layer(backend='threading', dtype=<class 'numpy.float32'>, n_jobs=-1,\n",
       "   name='layer-1', propagate_features=None, raise_on_exception=True,\n",
       "   random_state=4782, shuffle=False,\n",
       "   stack=[Group(backend='threading', dtype=<class 'numpy.float32'>,\n",
       "   indexer=FoldIndex(X=None, folds=2, raise_on_ex...7358DC8>)],\n",
       "   n_jobs=-1, name='group-1', raise_on_exception=True, transformers=[])],\n",
       "   verbose=1)],\n",
       "       model_selection=False, n_jobs=None, raise_on_exception=True,\n",
       "       random_state=555, sample_size=20,\n",
       "       scorer=<function accuracy_score at 0x0000016CC7358DC8>,\n",
       "       shuffle=False, verbose=2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit ensemble\n",
    "ensemble.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "Accuracy - Train :  0.8086404586404586\n",
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "Accuracy - Test :  0.8033169533169533\n"
     ]
    }
   ],
   "source": [
    "#pred_vals = ensemble.predict(X_test)\n",
    "print (\"Accuracy - Train : \", sklearn.metrics.accuracy_score(ensemble.predict(X_train), y_train))\n",
    "print (\"Accuracy - Test : \", sklearn.metrics.accuracy_score(ensemble.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit data:\n",
      "                                 score-m  score-s  ft-m  ft-s  pt-m  pt-s\n",
      "layer-1  kneighborsclassifier       0.77     0.00  0.25  0.03  1.18  0.03\n",
      "layer-1  logisticregression         0.79     0.00  0.71  0.00  0.01  0.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Fit data:\\n%r\" % ensemble.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's try some GridSearch\n",
    "\n",
    "xg_params = {\n",
    "    'eta': [0.01, 0.025, 0.05, 0.075, 0.25, 0.3, 0.5],\n",
    "    'max_depth': [3, 5, 6, 7, 9],\n",
    "    'tree_method': ['auto']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "seed = 555\n",
    "#kfold = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 35 candidates, totalling 175 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:   17.5s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:   21.6s\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed:   26.6s\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:   31.3s\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:   37.5s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   42.1s\n",
      "[Parallel(n_jobs=-1)]: Done 129 tasks      | elapsed:   48.2s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   55.0s\n",
      "[Parallel(n_jobs=-1)]: Done 175 out of 175 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, random_state=None,\n",
       "                                     reg_alpha=None, reg_lambda=None,\n",
       "                                     scale_pos_weight=None, seed=555,\n",
       "                                     subsample=None, tree_method=None,\n",
       "                                     validate_parameters=None, verbosity=None),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'eta': [0.01, 0.025, 0.05, 0.075, 0.25, 0.3, 0.5],\n",
       "                         'max_depth': [3, 5, 6, 7, 9],\n",
       "                         'tree_method': ['auto']},\n",
       "             scoring='roc_auc', verbose=10)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_XGB = XGBClassifier(n_estimators = 100, objective= 'binary:logistic', seed=555)\n",
    "grid2 = GridSearchCV(clf_XGB, xg_params, scoring=\"roc_auc\", cv=5, verbose=10, n_jobs=-1)\n",
    "grid2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'eta': 0.25, 'max_depth': 3, 'tree_method': 'auto'}\n",
      "Accuracy - Train CV:  0.8699017199017198\n",
      "Accuracy - Train :  0.8770270270270271\n",
      "Accuracy - Test :  0.8716216216216216\n"
     ]
    }
   ],
   "source": [
    "print ('Best Parameters: ', grid2.best_params_)\n",
    "results = sklearn.model_selection.cross_val_score(grid2.best_estimator_, X_train,y_train, cv=5)\n",
    "print (\"Accuracy - Train CV: \", results.mean())\n",
    "print (\"Accuracy - Train : \", sklearn.metrics.accuracy_score(grid2.best_estimator_.predict(X_train), y_train))\n",
    "print (\"Accuracy - Test : \", sklearn.metrics.accuracy_score(grid2.best_estimator_.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
