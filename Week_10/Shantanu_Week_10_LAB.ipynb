{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlens\n",
      "  Downloading mlens-0.2.3-py2.py3-none-any.whl (227 kB)\n",
      "Requirement already satisfied: scipy>=0.17 in c:\\users\\hp\\appdata\\local\\conda\\conda\\envs\\tf2\\lib\\site-packages (from mlens) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.11 in c:\\users\\hp\\appdata\\local\\conda\\conda\\envs\\tf2\\lib\\site-packages (from mlens) (1.16.2)\n",
      "Installing collected packages: mlens\n",
      "Successfully installed mlens-0.2.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.2; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the 'c:\\users\\hp\\appdata\\local\\conda\\conda\\envs\\tf2\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "### You will need mlens package in addition to the libraries you are familiar with\n",
    "# !pip install mlens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WEEK 10 LAB: \n",
    "1. LOOP THROUGH MODELS AS DONE IN THIS WEEK'S CLASS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for clf, label in zip([LR, RF, KNC, DTC, ABC, BC, GBC, XGB],\n",
    "#                       ['Logistic Regression',\n",
    "#                        'Random Forest',\n",
    "#                        'KNeighbors',\n",
    "#                        'Decision Tree',\n",
    "#                        'Ada Boost',\n",
    "#                        'Bagging',\n",
    "#                        'Gradient Boosting',\n",
    "#                        'XGBoost']):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>WorkClass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationNum</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>Race</th>\n",
       "      <th>Gender</th>\n",
       "      <th>CapitalGain</th>\n",
       "      <th>CapitalLoss</th>\n",
       "      <th>HoursPerWeek</th>\n",
       "      <th>NativeCountry</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>257302</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>154374</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>151910</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>201490</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>52</td>\n",
       "      <td>5</td>\n",
       "      <td>287927</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age  WorkClass  fnlwgt  Education  EducationNum  MaritalStatus  \\\n",
       "48837   27          4  257302          7            12              2   \n",
       "48838   40          4  154374         11             9              2   \n",
       "48839   58          4  151910         11             9              6   \n",
       "48840   22          4  201490         11             9              4   \n",
       "48841   52          5  287927         11             9              2   \n",
       "\n",
       "       Occupation  Relationship  Race  Gender  CapitalGain  CapitalLoss  \\\n",
       "48837          13             5     4       0            0            0   \n",
       "48838           7             0     4       1            0            0   \n",
       "48839           1             4     4       0            0            0   \n",
       "48840           1             3     4       1            0            0   \n",
       "48841           4             5     4       0        15024            0   \n",
       "\n",
       "       HoursPerWeek  NativeCountry  Income  \n",
       "48837            38             39       0  \n",
       "48838            40             39       1  \n",
       "48839            40             39       0  \n",
       "48840            20             39       0  \n",
       "48841            40             39       1  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "from sklearn.svm import SVC\n",
    "import sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "col_names = [\n",
    "    \"Age\", \"WorkClass\", \"fnlwgt\", \"Education\", \"EducationNum\",\n",
    "    \"MaritalStatus\", \"Occupation\", \"Relationship\", \"Race\", \"Gender\",\n",
    "    \"CapitalGain\", \"CapitalLoss\", \"HoursPerWeek\", \"NativeCountry\", \"Income\"\n",
    "]\n",
    "\n",
    "df = pandas.read_csv('census_data.csv')\n",
    "df.columns=col_names\n",
    "# df['Income'] = df['Income'].apply(lambda x: 0 if x == '<=50K' else 1)\n",
    "\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == type(object):\n",
    "        le = sklearn.preprocessing.LabelEncoder()\n",
    "        df[column] = le.fit_transform(df[column])\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Income'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='Income')\n",
    "y = df['Income']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=555, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Now Looping through the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.1.1-py3-none-win_amd64.whl (54.4 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\appdata\\local\\conda\\conda\\envs\\tf2\\lib\\site-packages (from xgboost) (1.16.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\hp\\appdata\\local\\conda\\conda\\envs\\tf2\\lib\\site-packages (from xgboost) (1.4.1)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.2; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the 'c:\\users\\hp\\appdata\\local\\conda\\conda\\envs\\tf2\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# !pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import statsmodels.api as sm\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold cross validation:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\HP\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\HP\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train CV Accuracy: 0.788 (+/- 0.004) [Logistic Regression]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7875 \n",
      "Train CV Accuracy: 0.857 (+/- 0.003) [Random Forest]\n",
      "Test Accuracy: 0.8569 \n",
      "Train CV Accuracy: 0.776 (+/- 0.003) [KNeighbors]\n",
      "Test Accuracy: 0.7750 \n",
      "Train CV Accuracy: 0.813 (+/- 0.004) [Decision Tree]\n",
      "Test Accuracy: 0.8161 \n",
      "Train CV Accuracy: 0.865 (+/- 0.004) [Ada Boost]\n",
      "Test Accuracy: 0.8641 \n",
      "Train CV Accuracy: 0.855 (+/- 0.005) [Bagging]\n",
      "Test Accuracy: 0.8547 \n",
      "Train CV Accuracy: 0.865 (+/- 0.004) [Gradient Boosting]\n",
      "Test Accuracy: 0.8667 \n",
      "Train CV Accuracy: 0.869 (+/- 0.005) [XGBoost]\n",
      "Test Accuracy: 0.8772 \n"
     ]
    }
   ],
   "source": [
    "LR = LogisticRegression(solver='lbfgs', random_state=555)\n",
    "RF = RandomForestClassifier(n_estimators = 100, random_state=555)\n",
    "SVM = SVC(random_state=0, probability=True)\n",
    "KNC = KNeighborsClassifier()\n",
    "DTC = DecisionTreeClassifier()\n",
    "ABC = AdaBoostClassifier(n_estimators = 100)\n",
    "BC = BaggingClassifier(n_estimators = 100)\n",
    "GBC = GradientBoostingClassifier(n_estimators = 100)\n",
    "clf_XGB = XGBClassifier(n_estimators = 100, objective= 'binary:logistic', seed=555)\n",
    "clfs = []\n",
    "print('5-fold cross validation:\\n')\n",
    "for clf, label in zip([LR, RF, KNC, DTC, ABC, BC, GBC, clf_XGB],\n",
    "                      ['Logistic Regression',\n",
    "                       'Random Forest',\n",
    "                       #'Support Vector Machine',\n",
    "                       'KNeighbors',\n",
    "                       'Decision Tree',\n",
    "                       'Ada Boost',\n",
    "                       'Bagging',\n",
    "                       'Gradient Boosting',\n",
    "                       'XGBoost']):\n",
    "    scores = sklearn.model_selection.cross_val_score(clf, X_train, y_train, cv=5, scoring=\"accuracy\")\n",
    "    print(\"Train CV Accuracy: %0.3f (+/- %0.3f) [%s]\" % (scores.mean(), scores.std(), label))\n",
    "    md = clf.fit(X_train, y_train)\n",
    "    clfs.append(md)\n",
    "    print(\"Test Accuracy: %0.4f \" % (sklearn.metrics.accuracy_score(clf.predict(X_test), y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. BUILD A CUSTOM ENSEMBLE (SUPERLEARNER) WITH ANY THREE OF THE MODELS IN TWO LAYERS.  IS IT BETTER?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building custom ensemble i.e. Superlearner with Random Forest and Logistics Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "from mlens.ensemble import SuperLearner\n",
    "from mlens.model_selection import Evaluator\n",
    "from mlens.metrics import make_scorer\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passing the scoring function\n",
    "ensemble = SuperLearner(scorer=accuracy_score, random_state=555, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuperLearner(array_check=None, backend=None, folds=2,\n",
       "       layers=[Layer(backend='threading', dtype=<class 'numpy.float32'>, n_jobs=-1,\n",
       "   name='layer-1', propagate_features=None, raise_on_exception=True,\n",
       "   random_state=4782, shuffle=False,\n",
       "   stack=[Group(backend='threading', dtype=<class 'numpy.float32'>,\n",
       "   indexer=FoldIndex(X=None, folds=2, raise_on_ex...CAED400>)],\n",
       "   n_jobs=-1, name='group-9', raise_on_exception=True, transformers=[])],\n",
       "   verbose=1)],\n",
       "       model_selection=False, n_jobs=None, raise_on_exception=True,\n",
       "       random_state=555, sample_size=20,\n",
       "       scorer=<function accuracy_score at 0x000001231CAED400>,\n",
       "       shuffle=False, verbose=2)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding layers using different methods such as Random Forest and Logistics Regression\n",
    "# Build the first layer\n",
    "ensemble.add([RF, LR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuperLearner(array_check=None, backend=None, folds=2,\n",
       "       layers=[Layer(backend='threading', dtype=<class 'numpy.float32'>, n_jobs=-1,\n",
       "   name='layer-1', propagate_features=None, raise_on_exception=True,\n",
       "   random_state=4782, shuffle=False,\n",
       "   stack=[Group(backend='threading', dtype=<class 'numpy.float32'>,\n",
       "   indexer=FoldIndex(X=None, folds=2, raise_on_ex...AED400>)],\n",
       "   n_jobs=-1, name='group-10', raise_on_exception=True, transformers=[])],\n",
       "   verbose=1)],\n",
       "       model_selection=False, n_jobs=None, raise_on_exception=True,\n",
       "       random_state=555, sample_size=20,\n",
       "       scorer=<function accuracy_score at 0x000001231CAED400>,\n",
       "       shuffle=False, verbose=2)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attaching the last layer meta estimator\n",
    "ensemble.add_meta(GradientBoostingClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting 2 layers\n",
      "Processing layer-1             "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done | 00:00:08\n",
      "Processing layer-2             done | 00:00:01\n",
      "Fit complete                        | 00:00:09\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SuperLearner(array_check=None, backend=None, folds=2,\n",
       "       layers=[Layer(backend='threading', dtype=<class 'numpy.float32'>, n_jobs=-1,\n",
       "   name='layer-1', propagate_features=None, raise_on_exception=True,\n",
       "   random_state=4782, shuffle=False,\n",
       "   stack=[Group(backend='threading', dtype=<class 'numpy.float32'>,\n",
       "   indexer=FoldIndex(X=None, folds=2, raise_on_ex...AED400>)],\n",
       "   n_jobs=-1, name='group-10', raise_on_exception=True, transformers=[])],\n",
       "   verbose=1)],\n",
       "       model_selection=False, n_jobs=None, raise_on_exception=True,\n",
       "       random_state=555, sample_size=20,\n",
       "       scorer=<function accuracy_score at 0x000001231CAED400>,\n",
       "       shuffle=False, verbose=2)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the ensemble\n",
    "ensemble.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:01\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:01\n",
      "Accuracy - Train :  0.9998908028718845\n",
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "Accuracy - Test :  0.856932274179019\n"
     ]
    }
   ],
   "source": [
    "# Printing the accuracy\n",
    "print (\"Accuracy - Train : \", sklearn.metrics.accuracy_score(ensemble.predict(X_train), y_train))\n",
    "print (\"Accuracy - Test : \", sklearn.metrics.accuracy_score(ensemble.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit data:\n",
      "                                   score-m  score-s  ft-m  ft-s  pt-m  pt-s\n",
      "layer-1  logisticregression           0.79     0.01  1.42  0.33  0.01  0.00\n",
      "layer-1  randomforestclassifier       0.86     0.00  4.43  0.18  0.61  0.01\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Fit data:\\n%r\" % ensemble.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting 85.55% Accuracy for testing is pretty good for combining the two models but it is computationaly expensive\n",
    "# instead we can also use XGBoost which gives 86.39% of accuracy by just the single model which is less computationally expensive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. NOW ADD A PREPROCESSING METHOD OF YOUR CHOICE TO THE DATA BEFORE SEDNING TO YOUR CUSTOM ENSEMBLE FROM #3.  SHOW BOTH RESULTS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adult = pandas.read_csv('census_data.csv') #to avoid confusion using another df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding for cleaning the dataset in order to increase accuracy\n",
    "for column in df_adult.columns:\n",
    "    if df_adult[column].dtype == type(object):\n",
    "        le = sklearn.preprocessing.LabelEncoder()\n",
    "        df_adult[column] = le.fit_transform(df_adult[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>257302</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>154374</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>151910</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>201490</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>52</td>\n",
       "      <td>5</td>\n",
       "      <td>287927</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  workclass  fnlwgt  education  educational-num  marital-status  \\\n",
       "48837   27          4  257302          7               12               2   \n",
       "48838   40          4  154374         11                9               2   \n",
       "48839   58          4  151910         11                9               6   \n",
       "48840   22          4  201490         11                9               4   \n",
       "48841   52          5  287927         11                9               2   \n",
       "\n",
       "       occupation  relationship  race  gender  capital-gain  capital-loss  \\\n",
       "48837          13             5     4       0             0             0   \n",
       "48838           7             0     4       1             0             0   \n",
       "48839           1             4     4       0             0             0   \n",
       "48840           1             3     4       1             0             0   \n",
       "48841           4             5     4       0         15024             0   \n",
       "\n",
       "       hours-per-week  native-country  income  \n",
       "48837              38              39       0  \n",
       "48838              40              39       1  \n",
       "48839              40              39       0  \n",
       "48840              20              39       0  \n",
       "48841              40              39       1  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adult.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_adult.drop(columns='income')\n",
    "y = df_adult['income']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=555, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\HP\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Adding Preprocessing\n",
    "X_train.dropna(inplace=True)\n",
    "X_test.dropna(inplace=True)\n",
    "y_train.dropna(inplace=True)\n",
    "y_test.dropna(inplace=True)\n",
    "# Dropped all the NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting 2 layers\n",
      "Processing layer-1             "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done | 00:00:07\n",
      "Processing layer-2             done | 00:00:01\n",
      "Fit complete                        | 00:00:09\n",
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:01\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:01\n",
      "Accuracy - Train :  0.9998908028718845\n",
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "Accuracy - Test :  0.856932274179019\n"
     ]
    }
   ],
   "source": [
    "# Printing the accuracy of first model without cleaning\n",
    "ensemble.fit(X_train, y_train)\n",
    "\n",
    "print (\"Accuracy - Train : \", sklearn.metrics.accuracy_score(ensemble.predict(X_train), y_train))\n",
    "print (\"Accuracy - Test : \", sklearn.metrics.accuracy_score(ensemble.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Below result is after cleaning the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting 2 layers\n",
      "Processing layer-1             "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done | 00:00:08\n",
      "Processing layer-2             done | 00:00:01\n",
      "Fit complete                        | 00:00:10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SuperLearner(array_check=None, backend=None, folds=2,\n",
       "       layers=[Layer(backend='threading', dtype=<class 'numpy.float32'>, n_jobs=-1,\n",
       "   name='layer-1', propagate_features=None, raise_on_exception=True,\n",
       "   random_state=4782, shuffle=False,\n",
       "   stack=[Group(backend='threading', dtype=<class 'numpy.float32'>,\n",
       "   indexer=FoldIndex(X=None, folds=2, raise_on_ex...AED400>)],\n",
       "   n_jobs=-1, name='group-10', raise_on_exception=True, transformers=[])],\n",
       "   verbose=1)],\n",
       "       model_selection=False, n_jobs=None, raise_on_exception=True,\n",
       "       random_state=555, sample_size=20,\n",
       "       scorer=<function accuracy_score at 0x000001231CAED400>,\n",
       "       shuffle=False, verbose=2)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the ensemble after cleaning dataset\n",
    "ensemble.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below accuracy is after data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:01\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:01\n",
      "Accuracy - Train :  0.9998908028718845\n",
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "Accuracy - Test :  0.856932274179019\n"
     ]
    }
   ],
   "source": [
    "# Printing the accuracy by data cleaning\n",
    "print (\"Accuracy - Train : \", sklearn.metrics.accuracy_score(ensemble.predict(X_train), y_train))\n",
    "print (\"Accuracy - Test : \", sklearn.metrics.accuracy_score(ensemble.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the given dataset training using custom ensemble with great models gave the same results even when the dataset was \n",
    "# cleaned by one hot encoding and removing NA values got the same result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
