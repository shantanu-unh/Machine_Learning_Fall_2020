{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <h2 align=\"center\">Machine Learning</h2> \n",
    "<h3 align=\"center\">Travis Millburn<br>Fall 2020</h3> \n",
    "\n",
    "<center>\n",
    "<img src=\"../images/logo.png\" alt=\"drawing\" style=\"width: 300px;\"/>\n",
    "</center>\n",
    "\n",
    "<h3 align=\"center\">Week 14: Deep Learning (Continued)</h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outline\n",
    "1. Plan / Schedule for Rest Remainder of Semester\n",
    "2. Deep Learning Concepts Continuation.  Introduction to CNN.\n",
    "3. No Lab.  Time given to projects: 2 hrs dedicated to projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projects\n",
    "\n",
    "Requirements - Review: \n",
    "1. Must be python, delivered in Jupyter notebook.\n",
    "2. Must be supervised learning problem.\n",
    "\n",
    "Rubric:\n",
    "1. Data selection interesting/challenging?\n",
    "2. Method interesting/challenging/thorough?\n",
    "3. Validation thorough, done properly?\n",
    "4. Report - well-written/understandable, explains pros/cons of method, what happened & why (can use jupyter completely if use markdown & latex).\n",
    "\n",
    "Note: some related tasks will go into participation or homework grade.\n",
    "\n",
    "HW-13 due today.  Presentations next class: 12/7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Schedule For Remainder of Semester\n",
    "* 11/30  No Class: Thanksgiving Break\n",
    "* 12/7   Zoom Project Presentations\n",
    "* 12/14  Final Exam (online)  AND   Submission of final project files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New Kaggle Competition Posted:\n",
    "    https://www.kaggle.com/c/jane-street-market-prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation Functions Revisited\n",
    "\n",
    "* Binary Step Function:  Threshold used.  Neuron activated or not based upon that threshold.  \n",
    "* Sigmoid:  Just like when we used it with logistical regression (classification) -- S shaped curve\n",
    "* Tanh Hyperbolic tangent:  Also s-shaped and continuous but has range from -1 to 1.  \n",
    "* ReLU Rectified Linear Unit max(0, z): Continuous (not differentiable) and very fast to compute.  \n",
    "\n",
    "\n",
    "<center>\n",
    "<img src=\"../images/activation_func.png\" alt=\"drawing\" style=\"width: 1000px;\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../images/tf_tour.png\" alt=\"drawing\" style=\"width: 1000px;\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"At the lowest level, each TensorFlow operation (op for short) is implemented using highly efficient C++ code. Many operations have multiple implementations called kernels: each kernel is dedicated to a specific device type, such as CPUs, GPUs, or even TPUs (tensor processing units).\"  \n",
    "-- Aurelien Geron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../images/tf_arch.png\" alt=\"drawing\" style=\"width: 1000px;\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF Data Preprocessing  \n",
    "* tf.io.decode_csv() -- Helpful for parsing .csv files.  Similar to functionality in sklearn\n",
    "* prefetch() -- Improve performance dramatically by saturating CPU and GPU resources\n",
    "<center>\n",
    "<img src=\"../images/prefetch_no_prefetch.png\" alt=\"drawing\" style=\"width: 1000px;\"/>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional neural networks (CNNs)\n",
    "* Sub-category of Neural Networks\n",
    "* Increased data and computing power have led to amazing CNN abilities.  Self driving cars!\n",
    "* Portions of the input (specific aspects) are given weights/importance, thus reducing preprocessing.\n",
    "* Significantly better efficacy than Multi Layer Perceptrons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Why not simply use a deep neural network with fully connected layers for image recognition tasks? Unfortunately, although this works fine for small images (e.g., MNIST), it breaks down for larger images because of the huge number of parameters it requires. For example, a 100 × 100–pixel image has 10,000 pixels, and if the first layer has just 1,000 neurons (which already severely restricts the amount of information transmitted to the next layer), this means a total of 10 million connections. And that’s just the first layer. CNNs solve this problem using partially connected layers and weight sharing.\"\n",
    "-- Aurelien Geron\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNNs use convolutional layers.  We need CNNs when the images get larger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### \"The role of the ConvNet is to reduce the images into a form which is easier to process, without losing features which are critical for getting a good prediction.\"\n",
    "\n",
    "<center>\n",
    "<img src=\"../images/cnn_vs_ann.png\" alt=\"drawing\" style=\"width: 1000px;\"/>\n",
    "</center>\n",
    "\n",
    "source: https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../images/cnn_train.png\" alt=\"drawing\" style=\"width: 1000px;\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../images/cnn_layers.png\" alt=\"drawing\" style=\"width: 1000px;\"/>\n",
    "</center>\n",
    "\n",
    "source: https://www.cs.ryerson.ca/~aharley/vis/conv/flat.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../images/cnn_layer2.png\" alt=\"drawing\" style=\"width: 1000px;\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the next class:\n",
    "* Additional linear algebra math behind traditional ML (shallow learners)\n",
    "* More advanced CNNs.  \n",
    "* Reinforcement Learning - optimization of rewards\n",
    "* Optimization !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
